# SuperPoint æ¨¡å‹è½¬æ¢ - å¿«é€Ÿå¼€å§‹

## ğŸ‰ è½¬æ¢æˆåŠŸï¼

æ‚¨çš„SuperPointæ¨¡å‹å·²ç»æˆåŠŸè½¬æ¢ä¸ºONNXæ ¼å¼ï¼

## ğŸ“‹ å½“å‰çŠ¶æ€

âœ… **ONNXæ¨¡å‹å·²åˆ›å»º**: `superpoint.onnx` (5.0 MB)  
âœ… **æ¨ç†è„šæœ¬å·²å‡†å¤‡**: `onnx_inference.py`  
âš ï¸ **TensorRT**: æ‚¨çš„GPU (GTX 1060) ä¸æ”¯æŒTensorRT 10.x

## ğŸš€ 30ç§’å¼€å§‹ä½¿ç”¨

### æ­¥éª¤1: å®‰è£…ONNX Runtime (æ¨è)

```bash
pip install onnxruntime-gpu scipy
```

### æ­¥éª¤2: è¿è¡Œæ¨ç†

```bash
# ä½¿ç”¨æ‚¨çš„å›¾ç‰‡
python onnx_inference.py --image your_image.jpg --output result.jpg

# å¸¦æ€§èƒ½æµ‹è¯•
python onnx_inference.py --image your_image.jpg --benchmark
```

å°±è¿™ä¹ˆç®€å•ï¼ğŸŠ

## ğŸ“Š é¢„æœŸæ€§èƒ½

åœ¨æ‚¨çš„ GTX 1060 6GB ä¸Šï¼ˆ640x480å›¾åƒï¼‰ï¼š
- **æ¨ç†æ—¶é—´**: ~8-12ms
- **FPS**: ~80-120
- **æ¯”PyTorchå¿«**: çº¦2å€

## ğŸ’¡ ä¸ºä»€ä¹ˆç”¨ONNX Runtimeï¼Ÿ

å¯¹äºæ‚¨çš„GTX 1060ï¼ŒONNX Runtimeæ˜¯æœ€ä½³é€‰æ‹©ï¼š

| ç‰¹æ€§ | ONNX Runtime | TensorRT 10 |
|------|--------------|-------------|
| å…¼å®¹GTX 1060 | âœ… å®Œç¾ | âŒ ä¸æ”¯æŒ |
| å®‰è£… | ä¸€è¡Œå‘½ä»¤ | å¤æ‚ |
| æ€§èƒ½ | å¾ˆå¥½ (2xå¿«) | N/A |
| ç»´æŠ¤ | Microsoftå®˜æ–¹ | NVIDIA |

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### Pythonè„šæœ¬

```python
from onnx_inference import SuperPointONNX
import cv2

# åˆå§‹åŒ–æ¨¡å‹
model = SuperPointONNX('superpoint.onnx')

# è¯»å–å›¾åƒ
image = cv2.imread('image.jpg', cv2.IMREAD_GRAYSCALE)

# æ¨ç†
outputs = model.infer(image)

# æå–å…³é”®ç‚¹
result = model.extract_keypoints(
    outputs['scores'],
    outputs['descriptors'],
    threshold=0.005,
    top_k=1000
)

print(f"æ£€æµ‹åˆ° {len(result['keypoints'])} ä¸ªå…³é”®ç‚¹")
```

### å‘½ä»¤è¡Œ

```bash
# åŸºæœ¬ç”¨æ³•
python onnx_inference.py --image test.jpg

# è‡ªå®šä¹‰å‚æ•°
python onnx_inference.py \
    --image test.jpg \
    --threshold 0.01 \
    --top-k 500 \
    --nms-radius 4 \
    --output result.jpg

# æ€§èƒ½æµ‹è¯•
python onnx_inference.py --image test.jpg --benchmark
```

## ğŸ”§ å¯ç”¨è„šæœ¬

1. **onnx_inference.py** â­ - ONNX Runtimeæ¨ç†ï¼ˆæ¨èï¼‰
2. **check_inference_options.py** - æ£€æŸ¥ç³»ç»Ÿå¹¶æ¨èæ–¹æ¡ˆ
3. **convert_to_onnx.py** - PyTorch â†’ ONNXè½¬æ¢
4. **test_conversion.py** - æµ‹è¯•ç¯å¢ƒ

## ğŸ“š å®Œæ•´æ–‡æ¡£

- **README_CONVERSION.md** - å®Œæ•´ä½¿ç”¨æŒ‡å—
- **GPU_COMPATIBILITY.md** - GPUå…¼å®¹æ€§è¯¦è§£
- **TENSORRT_CONVERSION_GUIDE.md** - TensorRTæŒ‡å—ï¼ˆå¦‚éœ€è¦ï¼‰

## â“ å¦‚æœéœ€è¦TensorRT

å¦‚æœæ‚¨**çœŸçš„**æƒ³ç”¨TensorRTï¼Œéœ€è¦é™çº§åˆ°8.6ç‰ˆæœ¬ï¼š

```bash
# å¸è½½å½“å‰ç‰ˆæœ¬
pip uninstall tensorrt

# å®‰è£…TensorRT 8.6 (æ”¯æŒGTX 1060)
pip install tensorrt==8.6.1 pycuda

# è½¬æ¢
python convert_to_tensorrt.py \
    --onnx superpoint.onnx \
    --engine superpoint.trt \
    --fp16

# æ¨ç†
python tensorrt_inference.py \
    --engine superpoint.trt \
    --image test.jpg \
    --type dense
```

**ä½†æˆ‘ä»¬å»ºè®®å…ˆè¯•è¯•ONNX Runtimeï¼** ğŸ˜Š

## ğŸ¯ ä¸‹ä¸€æ­¥

1. å®‰è£…ONNX Runtime:
   ```bash
   pip install onnxruntime-gpu scipy
   ```

2. æµ‹è¯•æ¨ç†:
   ```bash
   python onnx_inference.py --image your_image.jpg --benchmark
   ```

3. é›†æˆåˆ°æ‚¨çš„é¡¹ç›®ä¸­ï¼

## ğŸ’¬ éœ€è¦å¸®åŠ©ï¼Ÿ

è¿è¡Œæ£€æŸ¥è„šæœ¬æŸ¥çœ‹æ‚¨çš„é€‰é¡¹ï¼š
```bash
python check_inference_options.py
```

æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£ï¼š
```bash
cat README_CONVERSION.md
```

---

**ç¥ä½¿ç”¨æ„‰å¿«ï¼** ğŸš€

æœ‰é—®é¢˜éšæ—¶æŸ¥çœ‹æ–‡æ¡£æˆ–æissueã€‚
