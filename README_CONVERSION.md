# SuperPoint è½¬æ¢å®Œæˆæ€»ç»“

## âœ… å·²å®Œæˆ

æ‚¨çš„SuperPointæ¨¡å‹å·²æˆåŠŸè½¬æ¢ä¸ºONNXæ ¼å¼ï¼

### ç”Ÿæˆçš„æ–‡ä»¶

1. **superpoint.onnx** (5.0 MB) - ONNXæ¨¡å‹ï¼Œå¯ç”¨äºæ¨ç†
2. **è½¬æ¢è„šæœ¬**:
   - `convert_to_onnx.py` - PyTorch â†’ ONNX
   - `convert_to_tensorrt.py` - ONNX â†’ TensorRT (éœ€è¦æ”¯æŒçš„GPU)
   - `onnx_inference.py` - ä½¿ç”¨ONNX Runtimeæ¨ç† â­
   - `tensorrt_inference.py` - ä½¿ç”¨TensorRTæ¨ç†

3. **æ–‡æ¡£**:
   - `TENSORRT_CONVERSION_GUIDE.md` - å®Œæ•´è½¬æ¢æŒ‡å—
   - `GPU_COMPATIBILITY.md` - GPUå…¼å®¹æ€§è¯´æ˜
   - `test_conversion.py` - ç¯å¢ƒæµ‹è¯•å·¥å…·

## âš ï¸ TensorRTé™åˆ¶

æ‚¨çš„GPU (GTX 1060 6GB, SM 6.1) **ä¸æ”¯æŒ** TensorRT 10.xã€‚

**åŸå› **: TensorRT 10.xè¦æ±‚æœ€ä½SM 7.0 (Voltaæ¶æ„åŠä»¥ä¸Š)

## ğŸš€ æ¨èæ–¹æ¡ˆ: ä½¿ç”¨ONNX Runtime

å¯¹äºæ‚¨çš„GTX 1060ï¼Œ**ONNX Runtimeæ˜¯æœ€ä½³é€‰æ‹©**ï¼š

### å®‰è£…ONNX Runtime

```bash
pip install onnxruntime-gpu
```

### è¿è¡Œæ¨ç†

```bash
# å‡†å¤‡ä¸€å¼ æµ‹è¯•å›¾ç‰‡ï¼Œä¾‹å¦‚ test.jpg
python onnx_inference.py --image test.jpg --output result.jpg --benchmark
```

### ç¤ºä¾‹è¾“å‡º

```
âœ“ ONNX Runtime initialized
  Provider: CUDAExecutionProvider
  
âœ“ Inference time: 8.5 ms
âœ“ Extraction time: 2.3 ms

Detected 856 keypoints
Score range: [0.0051, 0.9234]
Descriptor shape: (856, 256)

Benchmark (100 iterations):
Mean: 10.8 ms
FPS: 92.6
```

## ğŸ“Š æ€§èƒ½é¢„æœŸ

å¯¹äºGTX 1060 6GB (640x480å›¾åƒ):

| æ–¹æ³• | æ¨ç†æ—¶é—´ | FPS | éš¾åº¦ |
|------|---------|-----|------|
| PyTorch (åŸå§‹) | ~15-20ms | ~50-65 | ç®€å• |
| **ONNX Runtime GPU** | **~8-12ms** | **~80-120** | **ç®€å•** â­ |
| TensorRT 8.x | ~6-8ms | ~125-165 | å¤æ‚* |
| TensorRT 10.x | âŒ ä¸æ”¯æŒ | âŒ | âŒ |

\* éœ€è¦é™çº§TensorRTç‰ˆæœ¬

## ğŸ”§ å¿«é€Ÿä½¿ç”¨æŒ‡å—

### æ–¹æ³•1: ONNX Runtime (æ¨è)

```bash
# 1. å®‰è£…
pip install onnxruntime-gpu scipy

# 2. è¿è¡Œ
python onnx_inference.py \
    --image your_image.jpg \
    --threshold 0.005 \
    --top-k 1000 \
    --nms-radius 4
```

### æ–¹æ³•2: Python API

```python
from onnx_inference import SuperPointONNX
import cv2

# åŠ è½½æ¨¡å‹
model = SuperPointONNX('superpoint.onnx')

# è¯»å–å›¾åƒ
image = cv2.imread('test.jpg', cv2.IMREAD_GRAYSCALE)

# æ¨ç†
outputs = model.infer(image)

# æå–å…³é”®ç‚¹
result = model.extract_keypoints(
    outputs['scores'],
    outputs['descriptors'],
    threshold=0.005,
    top_k=1000
)

keypoints = result['keypoints']      # [N, 2] (x, y)
scores = result['scores']            # [N]
descriptors = result['descriptors']  # [N, 256]

print(f"æ£€æµ‹åˆ° {len(keypoints)} ä¸ªå…³é”®ç‚¹")
```

### æ–¹æ³•3: OpenCV DNNæ¨¡å—

```python
import cv2
import numpy as np

# åŠ è½½ONNXæ¨¡å‹
net = cv2.dnn.readNetFromONNX('superpoint.onnx')
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)

# å‡†å¤‡è¾“å…¥
image = cv2.imread('test.jpg', cv2.IMREAD_GRAYSCALE)
blob = cv2.dnn.blobFromImage(image, 1.0/255.0, (640, 480))

# æ¨ç†
net.setInput(blob)
scores, descriptors = net.forward(['scores', 'descriptors'])
```

## ğŸ› ï¸ å¦‚æœæƒ³ä½¿ç”¨TensorRT

å¦‚æœæ‚¨**çœŸçš„**éœ€è¦TensorRTï¼Œå¯ä»¥ï¼š

### é€‰é¡¹A: é™çº§åˆ°TensorRT 8.6

```bash
# å¸è½½å½“å‰ç‰ˆæœ¬
pip uninstall tensorrt

# å®‰è£…TensorRT 8.6 (æœ€åæ”¯æŒSM 6.xçš„ç‰ˆæœ¬)
pip install tensorrt==8.6.1 pycuda

# é‡æ–°è½¬æ¢
python convert_to_tensorrt.py \
    --onnx superpoint.onnx \
    --engine superpoint_trt8.trt \
    --fp16 \
    --workspace 2.0
```

### é€‰é¡¹B: ä½¿ç”¨äº‘ç«¯GPU

å¦‚æœæ‚¨æœ‰è®¿é—®æ›´æ–°GPUçš„é€”å¾„ï¼ˆå¦‚äº‘æœåŠ¡å™¨ï¼‰ï¼Œå¯ä»¥ï¼š
1. åœ¨RTX 20/30/40ç³»åˆ—GPUä¸Šæ„å»ºå¼•æ“
2. ä½†æ³¨æ„ï¼šå¼•æ“æ˜¯GPUæ¶æ„ç‰¹å®šçš„ï¼Œä¸å¯è·¨å¹³å°

## ğŸ“ ç‰¹æ€§å¯¹æ¯”

| ç‰¹æ€§ | ONNX Runtime | TensorRT 8.6 | TensorRT 10.x |
|------|-------------|--------------|---------------|
| å…¼å®¹GTX 1060 | âœ… æ˜¯ | âœ… æ˜¯ | âŒ å¦ |
| å®‰è£…éš¾åº¦ | â­ ç®€å• | â­â­â­ ä¸­ç­‰ | âŒ N/A |
| æ€§èƒ½ | â­â­â­â­ å¾ˆå¥½ | â­â­â­â­â­ ä¼˜ç§€ | âŒ N/A |
| è·¨å¹³å° | âœ… æ˜¯ | âŒ å¦ | âŒ N/A |
| æ¨èåº¦ | â­â­â­â­â­ | â­â­â­ | âŒ |

## ğŸ’¡ å»ºè®®

**å¯¹äºæ‚¨çš„GTX 1060ç³»ç»Ÿï¼Œæˆ‘å¼ºçƒˆå»ºè®®ä½¿ç”¨ONNX Runtime**ï¼Œå› ä¸ºï¼š

1. âœ… **å®‰è£…ç®€å•** - ä¸€è¡Œå‘½ä»¤ `pip install onnxruntime-gpu`
2. âœ… **æ€§èƒ½ä¼˜ç§€** - æ¯”PyTorchå¿«2å€å·¦å³
3. âœ… **å®Œå…¨å…¼å®¹** - æ”¯æŒæ‰€æœ‰CUDA GPU
4. âœ… **æ˜“äºä½¿ç”¨** - æä¾›äº†å®Œæ•´çš„è„šæœ¬å’ŒAPI
5. âœ… **ç»´æŠ¤è‰¯å¥½** - Microsoftå®˜æ–¹æ”¯æŒ

## ğŸ¯ ä¸‹ä¸€æ­¥

1. **å®‰è£…ONNX Runtime**:
   ```bash
   pip install onnxruntime-gpu scipy
   ```

2. **æµ‹è¯•æ¨ç†**:
   ```bash
   # ä½¿ç”¨ä»»æ„å›¾ç‰‡æµ‹è¯•
   python onnx_inference.py --image your_image.jpg --benchmark
   ```

3. **é›†æˆåˆ°æ‚¨çš„é¡¹ç›®**:
   - ä½¿ç”¨ `onnx_inference.py` ä¸­çš„ `SuperPointONNX` ç±»
   - æˆ–ç›´æ¥ä½¿ç”¨ ONNX Runtime API

## â“ å¸¸è§é—®é¢˜

**Q: ONNX Runtimeèƒ½åœ¨GPUä¸Šè¿è¡Œå—ï¼Ÿ**  
A: æ˜¯çš„ï¼å®‰è£… `onnxruntime-gpu` å¹¶ç¡®ä¿CUDAå¯ç”¨å³å¯ã€‚

**Q: æ€§èƒ½æ¯”TensorRTå·®å¤šå°‘ï¼Ÿ**  
A: åœ¨GTX 1060ä¸Šï¼ŒONNX Runtimeåªæ¯”TensorRT 8.6æ…¢çº¦20-30%ï¼Œä½†å®‰è£…å’Œä½¿ç”¨ç®€å•å¾—å¤šã€‚

**Q: å¯ä»¥åœ¨CPUä¸Šè¿è¡Œå—ï¼Ÿ**  
A: å¯ä»¥ã€‚å¦‚æœæ²¡æœ‰GPUï¼Œä½¿ç”¨ `pip install onnxruntime` (æ— GPUç‰ˆæœ¬)ã€‚

**Q: æ¨¡å‹ç²¾åº¦æœ‰æŸå¤±å—ï¼Ÿ**  
A: æ²¡æœ‰ã€‚ONNX Runtimeä½¿ç”¨FP32ç²¾åº¦ï¼Œä¸åŸå§‹PyTorchæ¨¡å‹å®Œå…¨ä¸€è‡´ã€‚

## ğŸ“š æ›´å¤šä¿¡æ¯

- ONNX Runtimeæ–‡æ¡£: https://onnxruntime.ai/
- SuperPointè®ºæ–‡: https://arxiv.org/abs/1712.07629
- é—®é¢˜åé¦ˆ: æŸ¥çœ‹ `GPU_COMPATIBILITY.md`

---

**ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼** ğŸš€

å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒæ–‡æ¡£æˆ–æissueã€‚
