# GPUå…¼å®¹æ€§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

## é—®é¢˜

æ‚¨çš„ç³»ç»Ÿé…ç½®ï¼š
- **GPU**: NVIDIA GeForce GTX 1060 6GB
- **è®¡ç®—èƒ½åŠ›**: SM 6.1 (CUDA Compute Capability 6.1)
- **TensorRTç‰ˆæœ¬**: 10.15.1.29

**é”™è¯¯ä¿¡æ¯**:
```
Target GPU SM 61 is not supported by this TensorRT release
```

## åŸå› 

TensorRT 10.x ç‰ˆæœ¬åªæ”¯æŒä»¥ä¸‹GPUæ¶æ„ï¼š
- **SM 7.0+** (VoltaåŠæ›´æ–°æ¶æ„)
- ä¾‹å¦‚: RTX 2060/2070/2080, RTX 3060/3070/3080/3090, RTX 4060/4070/4080/4090, Tesla V100, A100ç­‰

GTX 1060 (SM 6.1, Pascalæ¶æ„) ä¸åœ¨æ”¯æŒåˆ—è¡¨ä¸­ã€‚

## è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: ä½¿ç”¨TensorRT 8.x (æ¨èç”¨äºæ‚¨çš„GPU)

TensorRT 8.6æ˜¯æœ€åæ”¯æŒPascalæ¶æ„(SM 6.x)çš„ç‰ˆæœ¬ã€‚

#### 1.1 å¸è½½å½“å‰TensorRT
```bash
pip uninstall tensorrt
sudo apt remove tensorrt* --purge  # å¦‚æœé€šè¿‡aptå®‰è£…çš„
```

#### 1.2 å®‰è£…TensorRT 8.6

ä»NVIDIAå®˜ç½‘ä¸‹è½½TensorRT 8.6:
https://developer.nvidia.com/tensorrt

æˆ–ä½¿ç”¨pipå®‰è£…:
```bash
# For CUDA 11.x
pip install tensorrt==8.6.1

# è¿˜éœ€è¦å®‰è£…
pip install pycuda
```

#### 1.3 é‡æ–°è¿è¡Œè½¬æ¢
```bash
python convert_to_tensorrt.py \
    --onnx superpoint.onnx \
    --engine superpoint.trt \
    --fp16 \
    --workspace 2.0 \
    --test
```

### æ–¹æ¡ˆ 2: åœ¨æ”¯æŒçš„GPUä¸Šæ„å»ºå¼•æ“

å¦‚æœæ‚¨æœ‰è®¿é—®RTX 20ç³»åˆ—æˆ–æ›´æ–°GPUçš„æƒé™ï¼š

1. åœ¨è¯¥æœºå™¨ä¸Šæ„å»ºTensorRTå¼•æ“
2. å°†`.trt`æ–‡ä»¶å¤åˆ¶åˆ°æ‚¨çš„GTX 1060ç³»ç»Ÿ
3. **æ³¨æ„**: å¼•æ“æ˜¯ç‰¹å®šäºGPUæ¶æ„çš„ï¼Œæ­¤æ–¹æ¡ˆä¸é€‚ç”¨

### æ–¹æ¡ˆ 3: ä½¿ç”¨ONNX Runtimeæ›¿ä»£TensorRT

ONNX Runtimeæ”¯æŒæ›´å¹¿æ³›çš„GPUï¼ŒåŒ…æ‹¬GTX 1060ï¼š

```bash
pip install onnxruntime-gpu
```

ä½¿ç”¨ONNX Runtimeè¿›è¡Œæ¨ç†ï¼š

```python
import onnxruntime as ort
import numpy as np
import cv2

# åˆ›å»ºæ¨ç†ä¼šè¯
session = ort.InferenceSession(
    "superpoint.onnx",
    providers=['CUDAExecutionProvider', 'CPUExecutionProvider']
)

# åŠ è½½å›¾åƒ
image = cv2.imread('test.jpg', cv2.IMREAD_GRAYSCALE)
image = image.astype(np.float32) / 255.0
image = image[np.newaxis, np.newaxis, :, :]

# æ¨ç†
outputs = session.run(None, {'image': image})
scores = outputs[0]
descriptors = outputs[1]
```

æ€§èƒ½æ¯”è¾ƒï¼ˆä¼°è®¡ï¼‰ï¼š
- PyTorch: ~15ms
- ONNX Runtime GPU: ~8-10ms
- TensorRT 8 (å¦‚æœå¯ç”¨): ~5-7ms

### æ–¹æ¡ˆ 4: ä»…ä½¿ç”¨ONNXæ¨¡å‹

ONNXæ¨¡å‹å·²ç»æˆåŠŸåˆ›å»ºï¼Œæ‚¨å¯ä»¥ï¼š

1. **ä½¿ç”¨ONNX Runtime** (æ¨è)
2. **ä½¿ç”¨OpenCV DNNæ¨¡å—**:
   ```python
   import cv2
   net = cv2.dnn.readNetFromONNX('superpoint.onnx')
   net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)
   net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)
   ```

3. **ä½¿ç”¨PyTorchåŠ è½½ONNX** (è¾ƒæ…¢ä½†ç®€å•)

## æ¨èè¡ŒåŠ¨

**å¯¹äºGTX 1060ç”¨æˆ·ï¼Œæˆ‘å¼ºçƒˆæ¨èæ–¹æ¡ˆ3 (ONNX Runtime)**:

### å¿«é€Ÿå¼€å§‹ - ONNX Runtime

1. å®‰è£…:
```bash
pip install onnxruntime-gpu
```

2. åˆ›å»ºç®€å•çš„æ¨ç†è„šæœ¬ `onnx_inference.py`:
```python
import onnxruntime as ort
import cv2
import numpy as np
from tensorrt_inference import visualize_keypoints

# åŠ è½½æ¨¡å‹
session = ort.InferenceSession(
    "superpoint.onnx",
    providers=['CUDAExecutionProvider', 'CPUExecutionProvider']
)

print(f"ä½¿ç”¨æä¾›è€…: {session.get_providers()}")

# åŠ è½½å›¾åƒ
image = cv2.imread('test.jpg')
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
gray_normalized = gray.astype(np.float32) / 255.0
input_tensor = gray_normalized[np.newaxis, np.newaxis, :, :]

# æ¨ç†
outputs = session.run(None, {'image': input_tensor})
scores_map = outputs[0][0]  # [H, W]
descriptors_map = outputs[1][0]  # [256, H/8, W/8]

# æå–å…³é”®ç‚¹
from scipy.ndimage import maximum_filter

# NMS
nms_radius = 4
max_score = maximum_filter(scores_map, size=nms_radius*2+1, mode='constant')
nms_mask = (scores_map == max_score)
scores_map = scores_map * nms_mask

# é˜ˆå€¼
threshold = 0.005
mask = scores_map > threshold
yx = np.argwhere(mask)
keypoints = yx[:, ::-1].astype(np.float32)  # (x, y)
kp_scores = scores_map[yx[:, 0], yx[:, 1]]

# Top-k
top_k = 1000
if len(keypoints) > top_k:
    indices = np.argsort(kp_scores)[::-1][:top_k]
    keypoints = keypoints[indices]
    kp_scores = kp_scores[indices]

print(f"æ£€æµ‹åˆ° {len(keypoints)} ä¸ªå…³é”®ç‚¹")

# å¯è§†åŒ–
vis = visualize_keypoints(image, keypoints, kp_scores)
cv2.imwrite('output_onnxruntime.jpg', vis)
print("ä¿å­˜ç»“æœåˆ° output_onnxruntime.jpg")
```

3. è¿è¡Œ:
```bash
python onnx_inference.py
```

## TensorRTç‰ˆæœ¬ä¸GPUæ”¯æŒå¯¹ç…§è¡¨

| TensorRTç‰ˆæœ¬ | æœ€ä½CUDAè®¡ç®—èƒ½åŠ› | æ”¯æŒçš„GPUç¤ºä¾‹ |
|-------------|-----------------|--------------|
| 10.x | SM 7.0+ | RTX 20/30/40ç³»åˆ—, V100, A100 |
| 8.6 | SM 5.3+ | GTX 10ç³»åˆ—, RTX 20/30ç³»åˆ— |
| 7.x | SM 5.3+ | GTX 10ç³»åˆ—åŠä»¥ä¸Š |

## æ£€æŸ¥æ‚¨çš„é€‰æ‹©

è¿è¡Œè¿™ä¸ªè„šæœ¬æŸ¥çœ‹å¯ç”¨é€‰é¡¹ï¼š
```bash
python3 << 'EOF'
import torch
print(f"GPU: {torch.cuda.get_device_name(0)}")
cap = torch.cuda.get_device_capability(0)
print(f"è®¡ç®—èƒ½åŠ›: {cap[0]}.{cap[1]}")

sm = cap[0] * 10 + cap[1]
print(f"\nSMç‰ˆæœ¬: {sm}")

if sm >= 70:
    print("âœ“ æ”¯æŒ TensorRT 10.x")
    print("âœ“ æ”¯æŒ TensorRT 8.x")
elif sm >= 53:
    print("âœ— ä¸æ”¯æŒ TensorRT 10.x")
    print("âœ“ æ”¯æŒ TensorRT 8.x (æ¨è)")
else:
    print("âœ— TensorRTæ”¯æŒå—é™")

print("\næ¨è: ONNX Runtime (é€‚ç”¨äºæ‰€æœ‰GPU)")
EOF
```

## æ€»ç»“

ç”±äºæ‚¨çš„GTX 1060ä¸æ”¯æŒTensorRT 10.x:

1. **æœ€ä½³é€‰æ‹©**: ä½¿ç”¨ONNX Runtime GPUï¼ˆå®‰è£…ç®€å•ï¼Œæ€§èƒ½å¥½ï¼‰
2. **å¤‡é€‰**: é™çº§TensorRTåˆ°8.6ç‰ˆæœ¬
3. **ç®€å•**: ç›´æ¥ä½¿ç”¨ONNXæ¨¡å‹é…åˆPyTorchæˆ–OpenCV

ONNXæ¨¡å‹å·²æˆåŠŸåˆ›å»ºå¹¶å¯ä»¥ä½¿ç”¨ï¼ğŸ‰
